{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqw3CN+pN3cCREzMTJ0Jsf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luquelab/lab-bioinformatics-workshops/blob/main/lab-bioinformatics-workshops/tree/main/protein_language_models/LAB_WORKSHOP_llm_embedding_plus_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to language models in bioinformatics\n",
        "\n",
        "In this hands-on, we will:\n",
        "- Use a **protein language model (PLM)** (ProtBert-BFD) to create **embeddings** of viral proteins.\n",
        "- Run a small **classifier** (multilayer perceptron, MLP) to predict functional categories.\n",
        "- Inspect the actual data objects (embeddings, predictions).\n",
        "\n",
        "**Key concepts**\n",
        "- **Neural network:** a stack of linear + non-linear transformations learned from data.\n",
        "- **Transformer:** an architecture that uses **self-attention** to relate all tokens (amino acids) to each other.\n",
        "- **Embedding:** a vector of numbers that encodes semantic/functional/structural information in a continuous space.\n",
        "- **Classifier (MLP):** a few dense layers that map embeddings to probabilities over categories.\n",
        "\n",
        "> We’ll introduce concepts as we go, right next to the code that uses them.\n"
      ],
      "metadata": {
        "id": "kMdvG4M7dFTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0) Housekeeping & file panel\n",
        "We’ll work in `/content`. The next cell removes Colab’s demo folder and prints where we are.  \n",
        "Use the left **Files** panel to upload your FASTA (drag-and-drop).\n"
      ],
      "metadata": {
        "id": "GfXp600Jd-0p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mq2S96qvsPA9"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "cd /content\n",
        "rm -rf sample_data\n",
        "echo \"Working dir:\"; pwd; ls -la\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1) Get the auxiliary code (GitHub clone)\n",
        "\n",
        "This notebook is based on the paper [**Large language models improve annotation of prokaryotic viral proteins**](https://www.nature.com/articles/s41564-023-01584-8) (Flamholz et al 2024).\n",
        "\n",
        "We’ll pull the project repository that contains the utility scripts we’ll use:\n",
        "\n",
        "- `scripts/embed_faa.py` — runs the **protein language model** (ProtBert-BFD) to produce embeddings  \n",
        "- `scripts/predict_function.py` — runs the **classifier (MLP)** to predict functional categories  \n",
        "- `plm_vpf_embed.yml` — the exact dependencies for the **embedding** environment (older stack)  \n",
        "\n",
        "> The python environments that we create next needs the repo’s YAML (`plm_vpf_embed.yml`). Cloning first ensures we can build that env.\n"
      ],
      "metadata": {
        "id": "yr4oJiCoe8zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "cd /content\n",
        "if [[ ! -d viral-protein-function-plm ]]; then\n",
        "  git clone https://github.com/kellylab/viral-protein-function-plm.git\n",
        "else\n",
        "  echo \"Repo already present.\"\n",
        "fi\n"
      ],
      "metadata": {
        "id": "r2neyI_UsS6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Environments for reproducibility\n",
        "We’ll use **two conda environments**:\n",
        "- **`plm_vpf_embed` (Python 3.7):** matches the older stack required by the embedding code (BioTransformers + Transformers 4.8.x).\n",
        "- **`plm_vpf_predict` (Python 3.10):** modern enough to install TensorFlow 2.12 for the classifier.\n",
        "\n",
        "> Pinning versions keeps today’s workshop stable even if upstream packages change.\n"
      ],
      "metadata": {
        "id": "-R7m4NeaeQDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "cd /content\n",
        "\n",
        "# Install Miniconda (clean reinstall)\n",
        "rm -rf /opt/conda\n",
        "wget -q -P /tmp https://repo.anaconda.com/miniconda/Miniconda3-py311_23.11.0-2-Linux-x86_64.sh\n",
        "bash /tmp/Miniconda3-py311_23.11.0-2-Linux-x86_64.sh -b -p /opt/conda\n",
        "rm -f /tmp/Miniconda3-py311_23.11.0-2-Linux-x86_64.sh\n",
        "\n",
        "# Create env from repo YAML (Py3.7 + bio-transformers stack)\n",
        "source /opt/conda/etc/profile.d/conda.sh\n",
        "conda env create -f /content/viral-protein-function-plm/plm_vpf_embed.yml\n",
        "\n",
        "# Lock versions that we know work for the old stack\n",
        "conda activate plm_vpf_embed\n",
        "python -m pip -q install --force-reinstall \\\n",
        "  \"numpy==1.18.5\" \"transformers==4.8.2\" \"tokenizers==0.10.3\" \\\n",
        "  \"huggingface_hub==0.0.12\" \"requests==2.31.0\"\n",
        "\n",
        "# Persist both HF endpoint vars so even ancient libs behave\n",
        "conda env config vars set HUGGINGFACE_CO_URL=\"https://huggingface.co\" HF_ENDPOINT=\"https://huggingface.co\"\n",
        "conda deactivate\n",
        "echo \"plm_vpf_embed created.\"\n"
      ],
      "metadata": {
        "id": "6mHMpSvKsVYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Prediction environment (TensorFlow 2.12)\n",
        "The classifier we’ll run later was written against TF 2.12. Newer Colab bases use Python 3.12, where TF 2.12 dependencies are not provided, so we create a clean **Py3.10** env specifically for predictions.\n"
      ],
      "metadata": {
        "id": "yL5_2P4zgUmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "source /opt/conda/etc/profile.d/conda.sh\n",
        "\n",
        "# Create the prediction env if it doesn't exist\n",
        "if ! conda env list | grep -q \"^plm_vpf_predict\"; then\n",
        "  conda create -y -n plm_vpf_predict python=3.10\n",
        "fi\n",
        "\n",
        "conda activate plm_vpf_predict\n",
        "python -m pip -q install --no-cache-dir \\\n",
        "  \"tensorflow==2.12.0\" \\\n",
        "  \"seaborn\" \\\n",
        "  \"scikit-learn==1.1.3\" \\\n",
        "  \"pandas\" \\\n",
        "  \"matplotlib\" \\\n",
        "  \"ipykernel\"\n",
        "\n",
        "python - <<'PY'\n",
        "import sys, tensorflow as tf, sklearn, pandas as pd, matplotlib\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"TF:\", tf.__version__, \"| sklearn:\", sklearn.__version__)\n",
        "PY\n"
      ],
      "metadata": {
        "id": "kyeGCBGZtgDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Transformers & model caching (ProtBert-BFD)\n",
        "To make the code robust, we download the model to the local filesystem so the old libraries can load it reliably and offline (going online will try to update them).\n",
        "\n",
        "We’ll use **ProtBert-BFD**, an artificial intelligence transformer model designed to read and understand protein sequences, similar to how language models handle words. It was trained using masked-language modeling, a method where parts of a protein sequence (like certain amino acids) are hidden, and the model learns to predict these missing parts.\n",
        "\n",
        "A transformer is a type of neural network that takes in a sequence and processes the whole sequence at once, instead of step by step. Transformers use attention mechanisms to decide which parts matter most for predicting the best output\n",
        "\n",
        "Specifically, ProtBert uses **self-attention**. The model looks at the entire input sequence and figures out how each part (say, each word) relates to every other part, not just the one before or after it. For example, it helps the model know that \"sky\" and \"blue\" are connected, even if they're far apart in the sentence.\n"
      ],
      "metadata": {
        "id": "xVpaQITsjBS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "# Use system Python for a modern huggingface_hub to snapshot the model\n",
        "/usr/bin/python3 -m pip -q install \"huggingface_hub>=0.16\"\n",
        "\n",
        "# Download to the shared cache\n",
        "SNAP=$(/usr/bin/python3 - <<'PY'\n",
        "from huggingface_hub import snapshot_download\n",
        "p = snapshot_download(\"Rostlab/prot_bert_bfd\")\n",
        "print(p)\n",
        "PY\n",
        ")\n",
        "\n",
        "echo \"Snapshot at: $SNAP\"\n",
        "\n",
        "# Copy snapshot files into a folder named exactly like the model ID inside the repo\n",
        "mkdir -p /content/viral-protein-function-plm/Rostlab/prot_bert_bfd\n",
        "cp -f \"$SNAP\"/* /content/viral-protein-function-plm/Rostlab/prot_bert_bfd/\n",
        "ls -l /content/viral-protein-function-plm/Rostlab/prot_bert_bfd\n"
      ],
      "metadata": {
        "id": "ZSPWRU04yyy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Inputs and file layout\n",
        "- **FASTA:** one or more protein sequences.\n",
        "- **OUT_DIR:** where results go during embedding, then we move it up to `/content` after prediction.\n",
        "\n",
        "Notes:\n",
        "- Avoid parentheses in filenames.\n",
        "- GPU helps during embedding, but CPU works too (just slower).\n",
        "- For speed, consider a small subset.\n"
      ],
      "metadata": {
        "id": "yn0dYkLWl9Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set your inputs (edit here)\n",
        "import os, sys\n",
        "\n",
        "FASTA_FILE = \"viral_proteins_sample.faa\"  # @param {type:\"string\"}\n",
        "OUT_DIR    = \"viral_proteins_sample_out\"  # @param {type:\"string\"}\n",
        "\n",
        "# Resolve paths exactly like the original\n",
        "if FASTA_FILE == \"test.faa\":\n",
        "    input_path = \"/content/viral-protein-function-plm/test/test.faa\"\n",
        "else:\n",
        "    input_path = f\"/content/{FASTA_FILE}\"\n",
        "    if not os.path.isfile(input_path):\n",
        "        raise FileNotFoundError(f\"{input_path} not found in /content — upload it via the left Files panel.\")\n",
        "\n",
        "out_path = OUT_DIR if OUT_DIR.strip() else \"output\"\n",
        "\n",
        "print(\"input_path:\", input_path)\n",
        "print(\"out_path  :\", out_path)\n",
        "\n",
        "# Export for bash cells (persist to the notebook process env)\n",
        "%env INPUT_PATH=$input_path\n",
        "%env OUT_PATH=$out_path\n"
      ],
      "metadata": {
        "id": "6G-554uCzZ61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Embeddings (what we’re about to compute)\n",
        "**Embeddings** turn each protein into a vector of numbers so that “similar” proteins (by sequence context and learned biology) end up **nearby** in a multidimensional space.\n",
        "\n",
        "Pipeline we run next:\n",
        "1. Tokenize proteins\n",
        "     - The sequence of amino acids (letters) in a protein is converted into a list of tokens, so the model can read and analyze it.\n",
        "2. Run ProtBert-BFD to produce **per-residue** representations.\n",
        "     - Each amino acid token is passed through the ProtBert-BFD model, which produces a set of numbers (an embedding) that represents the unique information about that amino acid in its context within the whole protein. This gives a vector for every residue (amino acid) in the sequence).\n",
        "3. Pool to a **per-protein** vector (e.g., mean across residues).\n",
        "     - To summarize the whole protein, all the per-residue vectors are combined (for example, by averaging) to get one single vector representing the entire protein's properties. This is called \"pooling\"\n",
        "4. Save a Python pickle: `{basename}_embeddings_dict.pkl` mapping sequence IDs to embedding vectors.\n",
        "    - The resulting vectors (called embeddings) are saved in a Python .pkl file\n",
        "\n",
        "> We can even pool per-protein vectors to get one single vector representing a whole genome (genome-language-models)."
      ],
      "metadata": {
        "id": "T-KDb_ELmWnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "source /opt/conda/etc/profile.d/conda.sh\n",
        "conda activate plm_vpf_embed\n",
        "\n",
        "# Force offline + legacy endpoints (belt & suspenders)\n",
        "export TRANSFORMERS_OFFLINE=1\n",
        "export HUGGINGFACE_CO_URL=\"https://huggingface.co\"\n",
        "export HF_ENDPOINT=\"https://huggingface.co\"\n",
        "\n",
        "# Ensure util sets env vars inside Python (idempotent)\n",
        "UTIL=\"/content/viral-protein-function-plm/scripts/protbert_bfd_embed_utils.py\"\n",
        "grep -q \"HUGGINGFACE_CO_URL\" \"$UTIL\" || python - <<'PY'\n",
        "import re\n",
        "p=\"/content/viral-protein-function-plm/scripts/protbert_bfd_embed_utils.py\"\n",
        "s=open(p,\"r\",encoding=\"utf-8\").read()\n",
        "inject=\"import os\\nos.environ.setdefault('HUGGINGFACE_CO_URL','https://huggingface.co')\\nos.environ.setdefault('HF_ENDPOINT','https://huggingface.co')\\n\"\n",
        "m=re.search(r\"^(from|import).*(?:\\n(?:from|import).*)*\", s, flags=re.MULTILINE)\n",
        "s = (s[:m.end()] + \"\\n\" + inject + s[m.end():]) if m else inject + s\n",
        "open(p,\"w\",encoding=\"utf-8\").write(s)\n",
        "print(\"Patched:\", p)\n",
        "PY\n",
        "\n",
        "# Make sure the local model folder exists (from Step 4)\n",
        "test -f /content/viral-protein-function-plm/Rostlab/prot_bert_bfd/config.json\n",
        "\n",
        "# Auto-detect GPU and pick num_gpus accordingly\n",
        "NUM_GPUS=$(python - <<'PY'\n",
        "try:\n",
        "    import torch\n",
        "    print(1 if torch.cuda.is_available() else 0)\n",
        "except Exception:\n",
        "    print(0)\n",
        "PY\n",
        ")\n",
        "echo \"Using num_gpus = $NUM_GPUS\"\n",
        "\n",
        "cd /content/viral-protein-function-plm\n",
        "python scripts/embed_faa.py -faa \"${INPUT_PATH:?Missing INPUT_PATH}\" -out \"${OUT_PATH:?Missing OUT_PATH}\" --num_gpus \"$NUM_GPUS\"\n",
        "echo \"Embedding done → /content/viral-protein-function-plm/${OUT_PATH}\"\n"
      ],
      "metadata": {
        "id": "BRzMXS9gztQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Peek into the embeddings we just created\n",
        "import os, pickle, numpy as np\n",
        "\n",
        "out_dir = os.environ.get(\"OUT_PATH\", \"environmental_genomes_subset_out\")\n",
        "repo_dir = \"/content/viral-protein-function-plm\"\n",
        "pkl_path = os.path.join(repo_dir, out_dir, os.path.basename(os.environ.get(\"INPUT_PATH\",\"\")).split(\".faa\")[0] + \"_embeddings_dict.pkl\")\n",
        "\n",
        "print(\"Embeddings file:\", pkl_path)\n",
        "assert os.path.exists(pkl_path), \"Embeddings pickle not found. Did the embedding step finish?\"\n",
        "\n",
        "emb = pickle.load(open(pkl_path, \"rb\"))\n",
        "print(f\"Number of proteins embedded: {len(emb):,}\")\n",
        "\n",
        "# Take one example\n",
        "first_id = next(iter(emb))\n",
        "vec = emb[first_id]\n",
        "arr = np.asarray(vec)\n",
        "\n",
        "print(\"\\nExample ID:\", first_id[:80], \"...\")\n",
        "print(\"Vector dtype/shape:\", arr.dtype, arr.shape)\n",
        "print(\"First 8 numbers:\", np.round(arr.ravel()[:8], 4))\n",
        "\n",
        "# Simple quality checks across all embeddings\n",
        "lengths = np.array([np.asarray(v).shape[-1] for v in emb.values()])\n",
        "print(\"\\nAll vectors have the same length?\", np.all(lengths == lengths[0]))\n",
        "print(\"Embedding dimension (D):\", int(lengths[0]))\n"
      ],
      "metadata": {
        "id": "fWkVZSNqoAbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What you’re seeing\n",
        "Each protein ID maps to a **D-dimensional vector** (often D≈**1024** for ProtBert-BFD). These numbers are not arbitrary, during pre-training, the model learned to place **functionally/contextually related** proteins closer in this space.\n",
        "\n",
        "Because we pooled per-residue representations to one vector per protein, every vector has the **same length**, independent of sequence length, perfect for feeding into a classifier (and comparable to what happens when we align sequences).\n"
      ],
      "metadata": {
        "id": "88YveQtboLzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) From embeddings to functions (Classifier Multilayer Perceptron).\n",
        "An **MLP (multilayer perceptron)** is a simple neural network classifier. It takes the embedding vector as input and passes it through 1–3 dense layers with non-linearities, ending in a **softmax** that outputs **probabilities** over categories.\n",
        "\n",
        "What you’ll get next:\n",
        "- `<basename>_predictions.csv` —> the **top prediction** for each protein.\n",
        "- `<basename>_probabilities.csv` —> full probability vector for each protein (one column per category).\n",
        "- `prediction_heatmap.png` — a quick visual summary.\n",
        "- `<basename>_protbert_bfd.pkl` — serialized embeddings\n",
        "\n",
        "> **Interpretation:** High top-1 probability + large margin to the second best class is generally more reliable than many near-ties.\n"
      ],
      "metadata": {
        "id": "jmXO09fXoktN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "source /opt/conda/etc/profile.d/conda.sh\n",
        "conda activate plm_vpf_predict\n",
        "\n",
        "# Reuse the variables from your inputs step; fall back to the common names if missing\n",
        "INPUT_PATH=\"${INPUT_PATH:-/content/environmental_genomes.faa}\"\n",
        "OUT_PATH=\"${OUT_PATH:-environmental_genomes_out}\"\n",
        "\n",
        "cd /content/viral-protein-function-plm\n",
        "python scripts/predict_function.py -faa \"$INPUT_PATH\" -out \"$OUT_PATH\" \\\n",
        "  --output_predictions --prediction_heatmap --output_embeddings\n",
        "\n",
        "# Match the original notebook: move the results dir up one level\n",
        "mv \"$OUT_PATH\" ../\n",
        "cd /content\n",
        "\n",
        "echo \"Results at /content/$OUT_PATH:\"\n",
        "ls -l \"/content/$OUT_PATH\" | sed -n '1,200p'\n"
      ],
      "metadata": {
        "id": "nvt8-Ub3-hbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect classifier outputs\n",
        "import os, pandas as pd\n",
        "\n",
        "out_dir = os.environ.get(\"OUT_PATH\", \"environmental_genomes_subset_out\")\n",
        "final_dir = f\"/content/{out_dir}\"\n",
        "\n",
        "# The notebook moved OUT_DIR up one level after prediction\n",
        "pred_csv = os.path.join(final_dir, os.path.basename(os.environ.get(\"INPUT_PATH\",\"\")).split(\".faa\")[0] + \"_predictions.csv\")\n",
        "probs_csv = os.path.join(final_dir, os.path.basename(os.environ.get(\"INPUT_PATH\",\"\")).split(\".faa\")[0] + \"_probabilities.csv\")\n",
        "\n",
        "print(\"Predictions file:\", pred_csv, \"| exists:\", os.path.exists(pred_csv))\n",
        "print(\"Probabilities file:\", probs_csv, \"| exists:\", os.path.exists(probs_csv))\n",
        "\n",
        "if os.path.exists(pred_csv):\n",
        "    preds = pd.read_csv(pred_csv)\n",
        "    display(preds.head(10))\n",
        "\n",
        "if os.path.exists(probs_csv):\n",
        "    probs = pd.read_csv(probs_csv, index_col=0)\n",
        "    print(\"\\nProbabilities shape:\", probs.shape)\n",
        "    # Show the top-5 most confident calls\n",
        "    top_conf = probs.max(axis=1).sort_values(ascending=False).head(5)\n",
        "    print(\"\\nTop-5 most confident proteins:\")\n",
        "    display(pd.DataFrame({\"max_prob\": top_conf}).join(preds.set_index(preds.columns[0]), how=\"left\"))\n"
      ],
      "metadata": {
        "id": "qyZRHBbgpFnH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}